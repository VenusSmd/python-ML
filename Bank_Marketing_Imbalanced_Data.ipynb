{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4840b42-6abd-4c8b-8db3-0c7400d6c57b",
   "metadata": {},
   "source": [
    "## \"Predictive Analytics and Insight Discovery in Bank Marketing Campaigns\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d38f5-2c44-40f8-acfa-a4015b705a13",
   "metadata": {},
   "source": [
    "In this project, we aim to analyze a dataset from a bank marketing campaign to uncover insights and patterns related to customer behavior and response to the campaign. Our objective is to conduct a thorough Exploratory Data Analysis (EDA) to identify key factors influencing clients' decisions to subscribe to a term deposit. Following the EDA, we will focus on developing and evaluating predictive models using Logistic Regression and Random Forest and Gradient Boosting Classifier to forecast client subscription outcomes effectively. These algorithms are chosen for their popularity and effectiveness in binary classification problems, such as predicting whether a client will subscribe to a term deposit. This targeted approach will not only provide valuable insights into the effectiveness of the marketing strategies employed but also enable the accurate prediction of potential subscribers, thereby optimizing future marketing efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4078a26-e5ce-40b2-be3f-27917014419b",
   "metadata": {},
   "source": [
    "Dataset References: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcfcc4f-847f-42f1-b8a4-ef461bea693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7aaae03-f694-44c2-899e-307b5e4811c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married        NaN      no     1506     yes   no   \n",
       "4   33           NaN   single        NaN      no        1      no   no   \n",
       "\n",
       "  contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0     NaN    5   may       261         1     -1         0      NaN  no  \n",
       "1     NaN    5   may       151         1     -1         0      NaN  no  \n",
       "2     NaN    5   may        76         1     -1         0      NaN  no  \n",
       "3     NaN    5   may        92         1     -1         0      NaN  no  \n",
       "4     NaN    5   may       198         1     -1         0      NaN  no  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv(\"bank-full.csv\", sep = \";\", na_values = \"unknown\")\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ed19d1f-4844-4d58-b3a8-3a9949a715b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
       "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5824d5df-68f8-436c-974b-e45eed87ea2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 17)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a2ea6-684f-4ed5-8c3e-ffbe2de1c5a8",
   "metadata": {},
   "source": [
    "The dataset contains 38172 records of clients without term deposit subscription and only 5021 records of clients with term deposit subscription. Clearly an imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfb57462-b423-4581-890b-9cdad7bd98e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "no     39922\n",
       "yes     5289\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d29e45-fc25-45cb-bfad-5abe37c62070",
   "metadata": {},
   "source": [
    "## Encoding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bba0e63b-fbcd-4cb0-9d0b-a2326f239d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping binary categorical variables to numeric values for easier processing\n",
    "# Mapping \"default\": \"no\" to 0 and \"yes\" to 1\n",
    "bank[\"default\"] = bank[\"default\"].map({\"no\": 0, \"yes\": 1})\n",
    "\n",
    "# Mapping \"housing\" loan status: \"no\" to 0 and \"yes\" to 1\n",
    "bank[\"housing\"] = bank[\"housing\"].map({\"no\": 0, \"yes\": 1})\n",
    "\n",
    "# Mapping \"personal\" loan status: \"no\" to 0 and \"yes\" to 1\n",
    "bank[\"loan\"] = bank[\"loan\"].map({\"no\": 0, \"yes\": 1})\n",
    "\n",
    "# Mapping the target variable \"y\" (term deposit subscription): \"no\" to 0 and \"yes\" to 1\n",
    "bank[\"y\"] = bank[\"y\"].map({\"no\": 0, \"yes\": 1})\n",
    "\n",
    "# Mapping ordinal categorical variable \"education\" to numeric values\n",
    "# This assigns an increasing value with the level of education\n",
    "bank.education = bank.education.map({\"primary\": 0, \"secondary\": 1, \"tertiary\": 2})\n",
    "\n",
    "# Converting the \"month\" column from string type to numeric type\n",
    "# This involves first converting the month abbreviations to datetime format, then extracting the month as a numeric value\n",
    "bank.month = pd.to_datetime(bank.month, format=\"%b\").dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "970544bc-1b27-4a62-9ffd-1d5d6dfea92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              0\n",
       "job            288\n",
       "marital          0\n",
       "education     1857\n",
       "default          0\n",
       "balance          0\n",
       "housing          0\n",
       "loan             0\n",
       "contact      13020\n",
       "day              0\n",
       "month            0\n",
       "duration         0\n",
       "campaign         0\n",
       "pdays            0\n",
       "previous         0\n",
       "poutcome     36959\n",
       "y                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a8e719c-e71e-4c4a-ba76-bc02b246c3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            int64\n",
       "job           object\n",
       "marital       object\n",
       "education    float64\n",
       "default        int64\n",
       "balance        int64\n",
       "housing        int64\n",
       "loan           int64\n",
       "contact       object\n",
       "day            int64\n",
       "month          int32\n",
       "duration       int64\n",
       "campaign       int64\n",
       "pdays          int64\n",
       "previous       int64\n",
       "poutcome      object\n",
       "y              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e98b815-a7d8-417f-8443-4f64c7176888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dropping columns with a high percentage of missing values or those not needed for analysis\n",
    "bank.drop([\"poutcome\", \"contact\"], axis=1, inplace=True)\n",
    "\n",
    "# Handling missing values in 'job' by marking them as 'unknown'\n",
    "# Convert 'job' to string type if it's not already, then fill missing values\n",
    "bank['job'] = bank['job'].astype(str)  # Ensure 'job' is of string type\n",
    "bank['job'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Handling missing values in 'education' by imputing with the mode\n",
    "# First, find the mode of the 'education' column\n",
    "education_mode = bank['education'].mode()[0]\n",
    "\n",
    "# Impute missing 'education' values with the mode\n",
    "bank['education'].fillna(education_mode, inplace=True)\n",
    "\n",
    "# Converting remaining categorical variables into dummy variables\n",
    "# This step is crucial for preparing the dataset for machine learning algorithms\n",
    "# Using 'drop_first=True' to avoid multicollinearity by removing the first level of each categorical variable\n",
    "bank = pd.get_dummies(bank, drop_first=True)\n",
    "\n",
    "# At this point, the dataset 'bank' is preprocessed: missing values are handled, and categorical variables are converted\n",
    "# The dataset is now ready for further analysis or modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcb7d6cd-fd15-4da2-9d2c-47adf30e9ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>...</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_nan</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>353</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>723</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>779</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>348</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  education  default  balance  housing  loan  day  month  duration  \\\n",
       "0    58        2.0        0     2143        1     0    5      5       261   \n",
       "1    44        1.0        0       29        1     0    5      5       151   \n",
       "2    33        1.0        0        2        1     1    5      5        76   \n",
       "3    47        1.0        0     1506        1     0    5      5        92   \n",
       "4    33        1.0        0        1        0     0    5      5       198   \n",
       "5    35        2.0        0      231        1     0    5      5       139   \n",
       "6    28        2.0        0      447        1     1    5      5       217   \n",
       "7    42        2.0        1        2        1     0    5      5       380   \n",
       "8    58        0.0        0      121        1     0    5      5        50   \n",
       "9    43        1.0        0      593        1     0    5      5        55   \n",
       "10   41        1.0        0      270        1     0    5      5       222   \n",
       "11   29        1.0        0      390        1     0    5      5       137   \n",
       "12   53        1.0        0        6        1     0    5      5       517   \n",
       "13   58        1.0        0       71        1     0    5      5        71   \n",
       "14   57        1.0        0      162        1     0    5      5       174   \n",
       "15   51        0.0        0      229        1     0    5      5       353   \n",
       "16   45        1.0        0       13        1     0    5      5        98   \n",
       "17   57        0.0        0       52        1     0    5      5        38   \n",
       "18   60        0.0        0       60        1     0    5      5       219   \n",
       "19   33        1.0        0        0        1     0    5      5        54   \n",
       "20   28        1.0        0      723        1     1    5      5       262   \n",
       "21   56        2.0        0      779        1     0    5      5       164   \n",
       "22   32        0.0        0       23        1     1    5      5       160   \n",
       "23   25        1.0        0       50        1     0    5      5       342   \n",
       "24   40        0.0        0        0        1     1    5      5       181   \n",
       "25   44        1.0        0     -372        1     0    5      5       172   \n",
       "26   39        2.0        0      255        1     0    5      5       296   \n",
       "27   52        1.0        0      113        1     1    5      5       127   \n",
       "28   46        1.0        0     -246        1     0    5      5       255   \n",
       "29   36        1.0        0      265        1     1    5      5       348   \n",
       "\n",
       "    campaign  ...  job_management  job_nan  job_retired  job_self-employed  \\\n",
       "0          1  ...            True    False        False              False   \n",
       "1          1  ...           False    False        False              False   \n",
       "2          1  ...           False    False        False              False   \n",
       "3          1  ...           False    False        False              False   \n",
       "4          1  ...           False     True        False              False   \n",
       "5          1  ...            True    False        False              False   \n",
       "6          1  ...            True    False        False              False   \n",
       "7          1  ...           False    False        False              False   \n",
       "8          1  ...           False    False         True              False   \n",
       "9          1  ...           False    False        False              False   \n",
       "10         1  ...           False    False        False              False   \n",
       "11         1  ...           False    False        False              False   \n",
       "12         1  ...           False    False        False              False   \n",
       "13         1  ...           False    False        False              False   \n",
       "14         1  ...           False    False        False              False   \n",
       "15         1  ...           False    False         True              False   \n",
       "16         1  ...           False    False        False              False   \n",
       "17         1  ...           False    False        False              False   \n",
       "18         1  ...           False    False         True              False   \n",
       "19         1  ...           False    False        False              False   \n",
       "20         1  ...           False    False        False              False   \n",
       "21         1  ...            True    False        False              False   \n",
       "22         1  ...           False    False        False              False   \n",
       "23         1  ...           False    False        False              False   \n",
       "24         1  ...           False    False         True              False   \n",
       "25         1  ...           False    False        False              False   \n",
       "26         1  ...            True    False        False              False   \n",
       "27         1  ...           False    False        False              False   \n",
       "28         2  ...            True    False        False              False   \n",
       "29         1  ...           False    False        False              False   \n",
       "\n",
       "    job_services  job_student  job_technician  job_unemployed  \\\n",
       "0          False        False           False           False   \n",
       "1          False        False            True           False   \n",
       "2          False        False           False           False   \n",
       "3          False        False           False           False   \n",
       "4          False        False           False           False   \n",
       "5          False        False           False           False   \n",
       "6          False        False           False           False   \n",
       "7          False        False           False           False   \n",
       "8          False        False           False           False   \n",
       "9          False        False            True           False   \n",
       "10         False        False           False           False   \n",
       "11         False        False           False           False   \n",
       "12         False        False            True           False   \n",
       "13         False        False            True           False   \n",
       "14          True        False           False           False   \n",
       "15         False        False           False           False   \n",
       "16         False        False           False           False   \n",
       "17         False        False           False           False   \n",
       "18         False        False           False           False   \n",
       "19          True        False           False           False   \n",
       "20         False        False           False           False   \n",
       "21         False        False           False           False   \n",
       "22         False        False           False           False   \n",
       "23          True        False           False           False   \n",
       "24         False        False           False           False   \n",
       "25         False        False           False           False   \n",
       "26         False        False           False           False   \n",
       "27         False        False           False           False   \n",
       "28         False        False           False           False   \n",
       "29         False        False            True           False   \n",
       "\n",
       "    marital_married  marital_single  \n",
       "0              True           False  \n",
       "1             False            True  \n",
       "2              True           False  \n",
       "3              True           False  \n",
       "4             False            True  \n",
       "5              True           False  \n",
       "6             False            True  \n",
       "7             False           False  \n",
       "8              True           False  \n",
       "9             False            True  \n",
       "10            False           False  \n",
       "11            False            True  \n",
       "12             True           False  \n",
       "13             True           False  \n",
       "14             True           False  \n",
       "15             True           False  \n",
       "16            False            True  \n",
       "17             True           False  \n",
       "18             True           False  \n",
       "19             True           False  \n",
       "20             True           False  \n",
       "21             True           False  \n",
       "22            False            True  \n",
       "23             True           False  \n",
       "24             True           False  \n",
       "25             True           False  \n",
       "26            False            True  \n",
       "27             True           False  \n",
       "28            False            True  \n",
       "29            False            True  \n",
       "\n",
       "[30 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397dff8f-e4b9-464d-a41c-3b44f338eb5f",
   "metadata": {},
   "source": [
    "## \"Key Preprocessing Steps for Dataset Readiness\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c732cfa6-aca2-4fff-9543-a76ab5bf9232",
   "metadata": {},
   "source": [
    "1. Numeric and Encoded Features: The dataset includes both numeric features and one-hot encoded categorical features, making it suitable for machine learning models which require numerical input.\n",
    "\n",
    "2. Education Encoding: The education column is encoded numerically, with missing values imputed using the mode of the column. This ensures no missing values in a critical feature, maintaining data integrity for modeling.\n",
    "\n",
    "3. Dummy Variables Creation: Categorical variables such as job and marital status have been converted into dummy variables. This transformation allows models to interpret these as distinct categories without any ordinal relationship, enhancing model accuracy.\n",
    "\n",
    "4. Boolean Representation: The one-hot encoded columns are represented as boolean (True/False) values, indicating the presence or absence of a category. This efficient representation aids in simplifying the dataset structure for analysis.\n",
    "\n",
    "5. Explicit Handling of 'Unknown' Categories: The dataset includes a specific column (job_nan) for marking originally missing job information as 'unknown'. This explicit tracking allows for nuanced analysis or modeling that accounts for records with missing job data.\n",
    "\n",
    "6. Dataset Prepared for Analysis/Modeling: With preprocessing steps like missing value imputation, categorical variable encoding, and conversion to numeric formats completed, the dataset is well-prepared for detailed analysis or use in machine learning models, ensuring reliable and insightful outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f049043e-f64d-4c68-8840-134b8f032028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Count (target)'}, xlabel='y'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bank.y.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4885cbe-e86c-4d57-b0b7-a9ac9580c43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/venus/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/venus/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/venus/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/venus/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/venus/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (3.2.0)\n",
      "Downloading imbalanced_learn-0.12.0-py3-none-any.whl (257 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.7/257.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f46dd-ba47-42a7-b469-db561a7b64ec",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6d810-3a77-4e52-ae3d-3bb17f1391ac",
   "metadata": {},
   "source": [
    "\n",
    "We utilized SMOTE (Synthetic Minority Over-sampling Technique) in our analysis due to its effectiveness in addressing the challenge of class imbalance within our dataset. Class imbalance can significantly bias the model towards the majority class, reducing its ability to accurately predict minority class instances, which are often of greater interest. SMOTE helps by generating synthetic examples of the minority class, thereby balancing the class distribution without losing valuable information. This technique improves the model's ability to learn from both classes equally, enhancing overall prediction accuracy and reliability, especially for the minority class. By applying SMOTE, we aimed to create a more balanced training environment for our model, enabling it to perform better on underrepresented data and thus ensure more generalized and equitable predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a51d34e4-5d0e-4ee7-a6b2-c8e3cb1d0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# Assuming 'bank' is your preprocessed DataFrame and 'y' is the target variable column\n",
    "X = bank.drop('y', axis=1)  # Features\n",
    "y = bank['y']  # Target variable\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initializing SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Applying SMOTE on the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# You can now proceed with training your model on the balanced dataset\n",
    "# X_train_smote and y_train_smote contain the oversampled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd9b7fd5-6f9e-4b5b-81f7-8c6dd44ae983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31937, 31937])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23c942d0-a20a-4e0f-9b4c-6c68b42ac29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      7985\n",
      "           1       0.53      0.55      0.54      1058\n",
      "\n",
      "    accuracy                           0.89      9043\n",
      "   macro avg       0.74      0.74      0.74      9043\n",
      "weighted avg       0.89      0.89      0.89      9043\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7470  515]\n",
      " [ 474  584]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Random Forest model with class weights set to 'balanced'\n",
    "# This option uses the values of y to automatically adjust weights inversely proportional to class frequencies\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model using the oversampled training data\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fb452498-6bbb-4570-8119-3af371990a4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.94      7985\n",
      "           1       0.64      0.32      0.43      1058\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.78      0.65      0.68      9043\n",
      "weighted avg       0.88      0.90      0.88      9043\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7798  187]\n",
      " [ 722  336]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest model with class weights set to 'balanced'\n",
    "# This option uses the values of y to automatically adjust weights inversely proportional to class frequencies\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "\n",
    "# this time on X_train, y_train and NOT the smote ones to compare the results\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d16b65-0e71-4ada-8656-d8eed826a4fe",
   "metadata": {},
   "source": [
    "## Insights\n",
    "Impact of SMOTE: Applying SMOTE has made the RandomForestClassifier more adept at recognizing the minority class (subscriptions), as evidenced by the increased recall. This is beneficial in scenarios where capturing as many positive instances as possible is more important than avoiding false positives, such as in marketing campaigns where the cost of a false positive (sending a promotional material to a non-interested customer) is low compared to the missed opportunity of not identifying a potential subscriber.\n",
    "Trade-offs: The increase in recall for class 1 comes with a decrease in precision, which is a common trade-off in predictive modeling, especially on imbalanced datasets. The slight drop in overall accuracy is also part of this trade-off.\n",
    "Business Decision: The choice between these two models depends on the business objective. If the goal is to maximize the identification of potential subscribers (even at the cost of increasing marketing expenses due to false positives), the model trained on SMOTE data is preferable. However, if maintaining a higher precision to minimize costs is crucial, the model trained on the original dataset might be more appropriate.\n",
    "## Conclusion\n",
    "The comparison underscores the importance of aligning model selection and tuning with business objectives. Balancing techniques like SMOTE, combined with class weight adjustments, can significantly enhance a model's sensitivity to minority classes, a desirable attribute in many practical applications. However, it's essential to carefully consider the implications of increased false positives and overall model accuracy in the context of specific business costs and benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af95193-3e97-4cb3-bf5f-673295978595",
   "metadata": {},
   "source": [
    "## \"Addressing Class Imbalance with Random Over-Sampling\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d530101-5b63-4b27-8ba5-69b7da29ab7b",
   "metadata": {},
   "source": [
    "randomly duplicating instances of the minority class until both classes have the same number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0754541b-499e-48b7-87de-52e69e92882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Initialize the RandomOverSampler object\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Correctly use the fit_resample method to oversample the training data\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "00f04d12-874b-48ff-9b85-1fa88d10404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6309 1676]\n",
      " [ 298  760]]\n",
      "0.7817096096428177\n",
      "0.718336483931947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86      7985\n",
      "           1       0.31      0.72      0.44      1058\n",
      "\n",
      "    accuracy                           0.78      9043\n",
      "   macro avg       0.63      0.75      0.65      9043\n",
      "weighted avg       0.88      0.78      0.81      9043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venus/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_over, y_train_over)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d217522-3e8e-47ef-b30e-ac43c335dda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reglog</th>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.78171</td>\n",
       "      <td>0.718336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Balancing Method  Accuracy    Recall\n",
       "Reglog  Random Oversampling   0.78171  0.718336"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomover = pd.DataFrame({'Balancing Method': 'Random Oversampling',\n",
    "                      'Accuracy':accuracy_score(y_test, y_pred),\n",
    "                      \"Recall\": recall_score(y_test, y_pred)},index=[\"Reglog\"])\n",
    "randomover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fbf90d-84f2-477f-be9d-35d4b7ded98e",
   "metadata": {},
   "source": [
    "##  \"Addressing Class Imbalance with Random Under-Sampling\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5870431-01d9-4aa1-8d3e-6a31ecfc4dfa",
   "metadata": {},
   "source": [
    "randomly reducing the number of instances in the majority class until the classes have an equal number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e1f5a65-1a83-485b-9a13-ccd1b31dc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Initialize the RandomUnderSampler object\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Use the fit_resample method to undersample the training data\n",
    "X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1db3eed-0b8a-4f22-8ceb-0a75ac74cf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    4231\n",
       "1    4231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_under.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0c16143b-a733-449b-b7e1-08ae1ceb6a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6228 1757]\n",
      " [ 275  783]]\n",
      "0.7752958089129713\n",
      "0.7400756143667296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86      7985\n",
      "           1       0.31      0.74      0.44      1058\n",
      "\n",
      "    accuracy                           0.78      9043\n",
      "   macro avg       0.63      0.76      0.65      9043\n",
      "weighted avg       0.88      0.78      0.81      9043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venus/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_under, y_train_under)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5ab343a-a1a7-454d-944d-a5b4e643965c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reglog</th>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.775296</td>\n",
       "      <td>0.740076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing Method  Accuracy    Recall\n",
       "Reglog  Random Undersampling  0.775296  0.740076"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Randomunder = pd.DataFrame({'Balancing Method': 'Random Undersampling',\n",
    "                      'Accuracy':accuracy_score(y_test, y_pred),\n",
    "                      \"Recall\": recall_score(y_test, y_pred)},index=[\"Reglog\"])\n",
    "Randomunder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "819e5f37-52fc-4ebd-b697-ba8f0a3d2269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reglog</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.857569</td>\n",
       "      <td>0.520794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reglog</th>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.781710</td>\n",
       "      <td>0.718336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reglog</th>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.775296</td>\n",
       "      <td>0.740076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing Method  Accuracy    Recall\n",
       "Reglog                 SMOTE  0.857569  0.520794\n",
       "Reglog   Random Oversampling  0.781710  0.718336\n",
       "Reglog  Random Undersampling  0.775296  0.740076"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [smote,randomover, Randomunder]\n",
    "TrainingResult = pd.concat(frames)\n",
    "TrainingResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f8206-2ed6-474b-a5d4-99e54ef4934d",
   "metadata": {},
   "source": [
    "## \"Combining SMOTE and Tomek Links for Class Imbalance Correction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cfdfd6-d00f-4504-9d73-a585164f3904",
   "metadata": {},
   "source": [
    "This method employs SMOTETomek from the imbalanced-learn library, which integrates the Synthetic Minority Over-sampling Technique (SMOTE) for oversampling the minority class with Tomek Links for cleaning overlapping samples between classes. This dual approach not only addresses the imbalance by augmenting the minority class but also enhances the quality of the dataset by removing instances that may contribute to classification noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2acd785f-d4eb-4ad6-9781-eac104827294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Initialize the SMOTETomek object\n",
    "smotemek = SMOTETomek(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Use the fit_resample method to apply SMOTE followed by Tomek Links cleaning\n",
    "X_train_smt, y_train_smt = smotemek.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f95720e1-5b6a-4acd-a7c6-5146f3e6a557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    31136\n",
       "1    31136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c0ae826-26ec-4a16-a24e-d48cbf10bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6439 1546]\n",
      " [ 308  750]]\n",
      "0.7949795421873272\n",
      "0.7088846880907372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venus/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_smt, y_train_smt)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2951d11-5dc7-4fbb-b74a-2ba1b49d1160",
   "metadata": {},
   "source": [
    "## \"Training a Gradient Boosting Classifier on a Balanced Dataset\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f74dc7-d8ff-4c2b-bb27-7ab8f31cefca",
   "metadata": {},
   "source": [
    "This method involves using a Gradient Boosting Classifier (GBC) from sklearn's ensemble module, configured with specific hyperparameters such as the number of estimators, learning rate, and maximum depth of the trees. The model is trained on a dataset balanced through a combination of SMOTE and Tomek Links (as indicated by the variables X_train_smt and y_train_smt), which addresses class imbalance by oversampling the minority class and cleaning the overlapping samples between classes. Once trained, the model is used to make predictions on the test set. This approach leverages the powerful Gradient Boosting algorithm to learn from a more representative, balanced dataset, aiming to improve the model's predictive performance and generalizability, especially in scenarios where class imbalance might otherwise bias the model towards the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "93fb4a9f-637b-4dc1-9334-19e25392c3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      7985\n",
      "           1       0.48      0.63      0.54      1058\n",
      "\n",
      "    accuracy                           0.88      9043\n",
      "   macro avg       0.71      0.77      0.74      9043\n",
      "weighted avg       0.89      0.88      0.88      9043\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7266  719]\n",
      " [ 393  665]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model using the balanced dataset\n",
    "gbc.fit(X_train_smt, y_train_smt)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = gbc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e75fd53-52af-4176-82ac-7a4b07907ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      7985\n",
      "           1       0.52      0.56      0.54      1058\n",
      "\n",
      "    accuracy                           0.89      9043\n",
      "   macro avg       0.73      0.75      0.74      9043\n",
      "weighted avg       0.89      0.89      0.89      9043\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7266  719]\n",
      " [ 393  665]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Train the model using the balanced dataset\n",
    "rf_classifier.fit(X_train_smt, y_train_smt)\n",
    "\n",
    "# Predict on the test set and evaluate\n",
    "predictions_rf = rf_classifier.predict(X_test)\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0eeb4-d095-4dd5-94da-cd32d698664a",
   "metadata": {},
   "source": [
    "## Business Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6c4876-a204-4821-98ed-4dd462d68f0e",
   "metadata": {},
   "source": [
    "The insights of these models enable us to target our marketing more precisely, ensuring we focus our efforts and resources on the customers most likely to subscribe to our term deposits. By better identifying potential subscribers (and equally important, those unlikely to subscribe), we can optimize our marketing spend, improve customer engagement strategies, and ultimately enhance our subscription rates. This model not only aids in direct marketing efficiency but also provides strategic insights that can influence product development and customer service enhancements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
